\documentclass[11pt]{article}

%  USE PACKAGES  ---------------------- 
\usepackage[margin=0.7in,vmargin=1in]{geometry}
\usepackage{amsmath,amsthm,amsfonts}
\usepackage{amssymb}
\usepackage{fancyhdr}
\usepackage{enumerate}
\usepackage{mathtools}
\usepackage{hyperref,color}
\usepackage{enumitem,amssymb}
\newlist{todolist}{itemize}{4}
\setlist[todolist]{label=$\square$}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\done}{\rlap{$\square$}{\raisebox{2pt}{\large\hspace{1pt}\cmark}}%
\hspace{-2.5pt}}
\newcommand{\HREF}[2]{\href{#1}{#2}}
\usepackage{textcomp}
\usepackage{listings}
\lstset{
basicstyle=\small\ttfamily,
% columns=flexible,
upquote=true,
breaklines=true,
showstringspaces=false
}
%  -------------------------------------------- 


%  HEADER AND FOOTER (DO NOT EDIT) ----------------------
\newcommand{\problemnumber}{0}
\pagestyle{fancy}
\fancyhead{}

\newcommand{\newquestion}[1]{
\clearpage % page break and flush floats
\renewcommand{\problemnumber}{#1} % set problem number for header
\phantom{}  % Put something on the page so it shows
}
\fancyfoot[L]{IE 332}
\fancyfoot[C]{Assignment submission}
\fancyfoot[R]{Page \thepage}
\renewcommand{\footrulewidth}{0.4pt}

%  --------------------------------------------


%  COVER SHEET (FILL IN THE TABLE AS INSTRUCTED IN THE ASSIGNMENT) ----------------------
\newcommand{\addcoversheet}{
\clearpage
\thispagestyle{empty}
\vspace*{0.5in}

\begin{center}
\Huge{{\bf IE332 Project \#2}} % <-- replace with correct assignment #

Due: April 28th, 11:59pm EST % <-- replace with correct due date and time
\end{center}

\vspace{0.3in}

\noindent We have {\bf read and understood the assignment instructions}. We certify that the submitted work does not violate any academic misconduct rules, and that it is solely our own work. By listing our names below we acknowledge that any misconduct will result in appropriate consequences. 

\vspace{0.2in}

\noindent {\em ``As a Boilermaker pursuing academic excellence, I pledge to be honest and true in all that I do.
Accountable together -- we are Purdue.''}

\vspace{0.2in}

\begin{table}[h!]
  \begin{center}
    \label{tab:table1}
    \begin{tabular}{c|ccccc|c|c}
      Student & Algorithm Development & Complexity Analysis & Implementation & Performance Analysis/Testing & Report & Overall & DIFF\\
      \hline
      Arisa Kulkarni & 20 & 20 & 20 & 20 & 20 & 100 & 0\\
      Allie Ranaldi & 20 & 20 & 20 & 20 & 20 & 100 & 0\\
      Noah Morrison & 20 & 20 & 20 & 20 & 20 & 100 & 0\\
      Jonathan Papp & 20 & 20 & 20 & 20 & 20 & 100 & 0\\
      Emilio Pozas & 20 & 20 & 20 & 20 & 20 & 100 & 0\\
      \hline
      St Dev & 0 & 0 & 0 & 0 & 0 & 0 & 0
    \end{tabular}
  \end{center}
\end{table}

\vspace{0.2in}

\noindent Date: April 28,2023
}
%  -----------------------------------------

\begin{document}

\addcoversheet


%ASSIGNMENT BEGINS HERE
%TABLE OF CONTENTS
\newpage
\tableofcontents


%MAIN TEXT OF REPORT
\newpage
\section{Executive Summary}
The following report details the team's optimization algorithms for adversarial attacks on a binary image classifier. Given a pre-trained image classifier that determines if a given image is a dandelion or grass, the team created five different machine learning/optimization algorithms to fool the image classifier. Each algorithm has a specific weight based on the expected performance of the given imputed image. The machine learning and optimization algorithms provide a foundation that can be used in the real-world application of AI infrastructure in many different organizational domains. 

%Introduction & Objectives
\section{Introduction \& Objectives}
Machine learning algorithms are used to teach computers specific tasks; in this project, that task is a binary classification of images. These algorithms go through a training period to learn the information directly from trial and error. Each iteration of training improves performance. The training code was given to the team to evaluate and decide the best course of action to trick.

The objectives for the team was to:

\begin{enumerate}

\end{enumerate}


%Image Classifiers
\section{Image Classifiers}

%Aversary Attack Prevention
\section{Adversary Attack Prevention}

%Algorithm Explanation 
\section{Machine Learning and Optimization Algorithms}
\subsection{Fast Gradient Sign Method}
Fast Gradient Sign Method, or FGSM, was one method used for a child algorithm. It is used to adjust the images in order to trick the algorithm. It is meant to trick the image processor by creating a new image from an input image that appears identical to the original to the human eye, but will cause the processor to be incorrect. It accomplishes this by computing the gradients of a loss function and then uses the sign of the gradients to create a new image. The following codes show the FGSM function as attempted by the group. 

\begin{lstlisting}[language=R, frame=single]
install.packages("imager")
library(keras)
library(imager)

#This is for loading the model and the chosen image
model <- load_model_tf("C:/Users/Quesadilla/Documents/332/Project2/model/dandelion_model")
img <- image_load("C:/Users/Quesadilla/Documents/332/Project2/data-for-332.tar/data-for-332/data-for-332/data-for-332/dandelions/dandelion_yellow_flower_230715-1599547728.jpg")

#this is for getting the loss function to compute the gradient of
loss_fn <- function(y_true, y_pred){
  mean(k_categorical_crossentropy(y_true, y_pred))
}

#this computes the gradient of the loss function and returns a new image
fgsm <- function(model, x, y, esp = 0.01){
  grad_fn <- tf.GradientTape(loss_fn, model$trainable_weights)
  grad <- grad_fn(list(x, y))[[1]]
  
  x_adv <- x + esp * sign(grad)
  
  return(x_adv)
}
#this applies fgsm to the new image and runs it through the classifier
x_adv <- fgsm(model, img, 1, esp = 0.1)

pred <- model %>% predict(x_adv)

class_label <- class.ind2label(pred)
\end{lstlisting}

\subsection{Simulated Annealing}
Simulated Annealing algorithm takes a heuristic approach for optimization problems. It is modeled from the annealing procedure of metal working. This approach was taken due to the common problems of other optimization algorithms that simply check their neighbourhood solutions and may get stuck in local minima. The SA algorithm incorporates two iterative loops that are modeled after the annealing process and the Metropolis criterion. The metropolis criterion is used explicitly to avoid the trap of getting stuck in local extreme. As you can see Simulated Annealing is a pure optimization algorithm. To use it for the purposes of tricking the image classification the objective function would focus on finding the pixels it can change. 

\begin{lstlisting}[language=R, frame=single]

\end{lstlisting}

\subsection{Differential Evolution}

\subsection{Particle Swarm Optimization}
Particle Swarm Optimization is an algorithm that generates an adversarial image that holds the ability to trick an image classification model. This is done by simulating interaction and movement between a group of particles in a controlled space to find the most optimal solution. In this machine learning algorithm, the possible solutions are considered the particles. The particles interact with each other by adjusting its movement velocity based on the experiences the particle itself has encountered and the experiences that it has witnessed from its neighboring particles. The velocity of the particle is updated with every iteration of a nested loop.

\begin{lstlisting}[language=R, frame=single]

\end{lstlisting}

\subsection{Random Forest}

%Weighted Algorithm
\section{Weighted Algorithm}

%SOLUTION HIGHLIGHTS
\addcontentsline{toc}{section}{Solution Highlights}
\subsection{Solution Highlights}
Put solution highlights here.



%APPENDIX
\pagebreak
\section{Appendix}


\subsection{Testing/Correctness/Verification}
To test the algorithms, the group first observed the success of the training model itself, without any adversarial attacks. The group tested both the grass set and the dandelion set, and kept results separate. This provided control group scores for which to compare the score of the sub-algorithms. The group then repeated the process for the datasets with \\

\subsection{Runtime Complexity and Walltime}
put runtime complexity here


\subsection{Performance}
put performance results here.

\subsection{References}

Adversarial example using FGSM &nbsp;: &nbsp; Tensorflow Core. TensorFlow. (n.d.). Retrieved April 27, 2023, from https://www.tensorflow.org/tutorials/generative/adversarial_fgsm 

Rosebrock, A. (2021, April 17). Adversarial attacks with FGSM (fast gradient sign method). PyImageSearch. Retrieved April 27, 2023, from https://pyimagesearch.com/2021/03/01/adversarial-attacks-with-fgsm-fast-gradient-sign-method/#:~:text=Essentially%2C%20FGSM%20computes%20the%20gradients,image)%20that%20maximizes%20the%20loss. 


\end{document}